"""
tools.py

LangGraph Agentì—ì„œ ì‚¬ìš©í•˜ëŠ” ì™¸ë¶€ Tool ì •ì˜ ëª¨ë“ˆ.

ì´ íŒŒì¼ì€ LLMì´ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” Toolê³¼,
ê·¸ Toolì´ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì‹¤ì œ êµ¬í˜„ í•¨ìˆ˜ë¥¼ í¬í•¨í•œë‹¤.

í˜„ì¬ í¬í•¨ëœ Tool:
- rag_search:
    Pinecone ë²¡í„° DBë¥¼ ì‚¬ìš©í•´
    ì—ëŸ¬ ë¡œê·¸ / ì½”ë“œ / ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì§€ì‹(KB)ì„ ê²€ìƒ‰í•œë‹¤.

ì—­í•  ë¶„ë¦¬ ì›ì¹™:
- Agent(LLM)ëŠ” 'ì–¸ì œ ê²€ìƒ‰í• ì§€'ë§Œ íŒë‹¨í•œë‹¤.
- tools.pyëŠ” 'ì–´ë–»ê²Œ ê²€ìƒ‰í• ì§€'ë§Œ ì±…ì„ì§„ë‹¤.
"""
import os
from dotenv import load_dotenv
load_dotenv()
import sys
from langchain_aws import BedrockEmbeddings
from pinecone import Pinecone
from langchain_core.tools import tool
from typing import Optional

_embedder: Optional[BedrockEmbeddings] = None
_pinecone_index = None
_namespace: Optional[str] = None

def _require_env(name: str) -> str:
    v = os.getenv(name)
    if not v:
        raise RuntimeError(
            f"Missing required environment variable: {name}. "
            f"Set it in your .env or CI secrets before using rag_search."
        )
    return v

def get_embedder() -> BedrockEmbeddings:
    global _embedder
    if _embedder is not None:
        return _embedder

    model_id = _require_env("BEDROCK_EMBEDDING_MODEL_ID")
    region = _require_env("AWS_REGION")

    _embedder = BedrockEmbeddings(
        model_id=model_id,
        region_name=region,
        aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
        aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
    )
    return _embedder


def get_pinecone_index():
    global _pinecone_index, _namespace
    if _pinecone_index is not None:
        return _pinecone_index

    api_key = _require_env("PINECONE_API_KEY")
    index_name = _require_env("PINECONE_INDEX")
    _namespace = os.getenv("PINECONE_NAMESPACE", "dev")

    pc = Pinecone(api_key=api_key)
    _pinecone_index = pc.Index(index_name)
    return _pinecone_index

def rag_search(query: str, top_k: int = 3) -> str:
    """
    RAG ê²€ìƒ‰ ë„êµ¬
    - query: ì‚¬ìš©ì ì§ˆë¬¸ ë˜ëŠ” ì—ëŸ¬ ì‹œê·¸ë‹ˆì²˜
    - return: LLM í”„ë¡¬í”„íŠ¸ì— ë°”ë¡œ ë„£ì„ ìˆ˜ ìˆëŠ” ë¬¸ìì—´
    """
    embedder = get_embedder()
    index = get_pinecone_index()
    qvec = embedder.embed_query(query)
    namespace = _namespace or "dev"

    res = index.query(
        vector=qvec,
        top_k=top_k,
        namespace=namespace,
        include_metadata=True,
    )

    chunks = []
    for m in res["matches"]:
        md = m.get("metadata", {}) or {}
        chunks.append(
            f"- ({m['score']:.3f}) {md.get('source','?')}#{md.get('chunk_index','?')}\n"
            f"{md.get('text','')}"
        )

    return "\n\n".join(chunks)
# =====================================================
# 2) LangGraph / Agentìš© Tool ë˜í¼
# =====================================================
@tool("rag_search")
def rag_search_tool(query: str) -> str:
    """
    ì—ëŸ¬ ë¡œê·¸, ì½”ë“œ, ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ
    Pinecone ë²¡í„° DBì—ì„œ ê´€ë ¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì§€ì‹ì„ ê²€ìƒ‰í•œë‹¤.
    """
    print("[TOOL CALLED] rag_search:", query[:80])
    print("ğŸ› ï¸ TOOL ENTERED:", query, file=sys.stderr, flush=True)
    return rag_search(query, top_k=5)